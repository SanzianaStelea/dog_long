{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not important for the task. We keep it just temporary for inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m folder\u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m image_array\u001b[39m=\u001b[39m[]\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(folder):\n\u001b[0;32m      9\u001b[0m     input_path\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder, filename)\n\u001b[0;32m     10\u001b[0m     image\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mimread(input_path)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "folder= r\"images\"\n",
    "image_array=[]\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    input_path=os.path.join(folder, filename)\n",
    "    image=cv2.imread(input_path)\n",
    "    if image is None:\n",
    "        print(\"image not found\")\n",
    "        continue\n",
    "image_array.append(np.array(image))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have previosly created an csv file that contains the image_id and the answers to questions t01, t07 and t02 as weighted factors, for each image. See repository gz2_t01.csv. The code creates a new dataframe which labels every image to a main type (for question t01) according to the format used in the CustomImageDataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     objid  asset_id  \\\n",
      "0       587732591714893851     58957   \n",
      "1       588009368545984617    193641   \n",
      "2       587732484359913515     55934   \n",
      "3       587741723357282317    158501   \n",
      "4       587738410866966577    110939   \n",
      "...                    ...       ...   \n",
      "239690  587741490371625059    262969   \n",
      "239691  587731174917669027    275883   \n",
      "239692  587731512070177108    282536   \n",
      "239693  587731513145688256    284172   \n",
      "239694  588015507679805636    288961   \n",
      "\n",
      "        t01_smooth_or_features_a01_smooth_weighted_fraction  \\\n",
      "0                                                   0.000     \n",
      "1                                                   0.024     \n",
      "2                                                   0.780     \n",
      "3                                                   0.036     \n",
      "4                                                   0.767     \n",
      "...                                                   ...     \n",
      "239690                                              0.823     \n",
      "239691                                              0.541     \n",
      "239692                                              0.789     \n",
      "239693                                              0.531     \n",
      "239694                                              0.763     \n",
      "\n",
      "        t01_smooth_or_features_a02_features_or_disk_weighted_fraction  \\\n",
      "0                                                   0.988               \n",
      "1                                                   0.976               \n",
      "2                                                   0.139               \n",
      "3                                                   0.964               \n",
      "4                                                   0.186               \n",
      "...                                                   ...               \n",
      "239690                                              0.174               \n",
      "239691                                              0.263               \n",
      "239692                                              0.156               \n",
      "239693                                              0.278               \n",
      "239694                                              0.212               \n",
      "\n",
      "        t01_smooth_or_features_a03_star_or_artifact_weighted_fraction  \n",
      "0                                                   0.012              \n",
      "1                                                   0.000              \n",
      "2                                                   0.081              \n",
      "3                                                   0.000              \n",
      "4                                                   0.047              \n",
      "...                                                   ...              \n",
      "239690                                              0.003              \n",
      "239691                                              0.197              \n",
      "239692                                              0.055              \n",
      "239693                                              0.191              \n",
      "239694                                              0.025              \n",
      "\n",
      "[239695 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "img_dir=r\"images\"\n",
    "csv_file_number=r\"gz2_filename_mapping.csv\"\n",
    "csv_file_quest=r\"gz2_hart16.csv\"\n",
    "\n",
    "file_number=pd.read_csv(csv_file_number)\n",
    "file_quest=pd.read_csv(csv_file_quest)\n",
    "\n",
    "file_merge = file_quest.merge(file_number, left_on='dr7objid', right_on='objid')[['objid', 'asset_id', 't01_smooth_or_features_a01_smooth_weighted_fraction', 't01_smooth_or_features_a02_features_or_disk_weighted_fraction', 't01_smooth_or_features_a03_star_or_artifact_weighted_fraction']]\n",
    "\n",
    "print(file_merge)\n",
    "file_merge.to_csv('gz2_merge.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir=r\"images\"\n",
    "csv_file=r\"gz2_merge.csv\"\n",
    "\n",
    "file=pd.read_csv(csv_file)\n",
    "file['asset_id'] = file['asset_id'].astype(str) + \".jpg\"\n",
    "\n",
    "for ind in file.index:\n",
    "    input_path=os.path.join(img_dir, file['asset_id'][ind])\n",
    "    photo=cv2.imread(input_path)\n",
    "    if photo is None:\n",
    "        file.drop(ind, inplace=True)\n",
    "\n",
    "file.to_csv('existing_images.csv', index= False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          asset_id  t01_type\n",
      "0        58957.jpg       1.0\n",
      "1       193641.jpg       1.0\n",
      "2        55934.jpg       0.0\n",
      "3       158501.jpg       1.0\n",
      "4       110939.jpg       0.0\n",
      "...            ...       ...\n",
      "209734   30593.jpg       0.0\n",
      "209735   74398.jpg       0.0\n",
      "209736  151540.jpg       0.0\n",
      "209737  259387.jpg       0.0\n",
      "209738  262969.jpg       0.0\n",
      "\n",
      "[209739 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file.loc [file['t01_smooth_or_features_a01_smooth_weighted_fraction']>0.6, 't01_type'] = 0\n",
    "file.loc [file['t01_smooth_or_features_a02_features_or_disk_weighted_fraction']>0.6, 't01_type'] = 1\n",
    "file.loc [file['t01_smooth_or_features_a03_star_or_artifact_weighted_fraction']>=0.5, 't01_type'] = 2\n",
    " \n",
    "file.dropna(inplace=True)\n",
    "file.reset_index(drop=True, inplace=True)\n",
    "\n",
    "t01_file=file[['asset_id','t01_type']].copy()\n",
    "\n",
    "print(t01_file)\n",
    "t01_file.to_csv('unbalanced_t01.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12e04c48ff6cb41451d3b8f61eaea77fdbb7c6edbe7af91566c35ff3203c4846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
