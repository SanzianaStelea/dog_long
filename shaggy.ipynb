{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not important for the task. We keep it just temporary for inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m folder\u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m image_array\u001b[39m=\u001b[39m[]\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(folder):\n\u001b[0;32m      9\u001b[0m     input_path\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder, filename)\n\u001b[0;32m     10\u001b[0m     image\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mimread(input_path)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "folder= r\"images\"\n",
    "image_array=[]\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    input_path=os.path.join(folder, filename)\n",
    "    image=cv2.imread(input_path)\n",
    "    if image is None:\n",
    "        print(\"image not found\")\n",
    "        continue\n",
    "image_array.append(np.array(image))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will process our data. The code creates new dataframes which label every image to a type (for question t01, t02 and t07) according to the format used in the CustomImageDataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     objid  asset_id  \\\n",
      "0       587732591714893851     58957   \n",
      "1       588009368545984617    193641   \n",
      "2       587732484359913515     55934   \n",
      "3       587741723357282317    158501   \n",
      "4       587738410866966577    110939   \n",
      "...                    ...       ...   \n",
      "239690  587741490371625059    262969   \n",
      "239691  587731174917669027    275883   \n",
      "239692  587731512070177108    282536   \n",
      "239693  587731513145688256    284172   \n",
      "239694  588015507679805636    288961   \n",
      "\n",
      "        t01_smooth_or_features_a01_smooth_weighted_fraction  \\\n",
      "0                                                   0.000     \n",
      "1                                                   0.024     \n",
      "2                                                   0.780     \n",
      "3                                                   0.036     \n",
      "4                                                   0.767     \n",
      "...                                                   ...     \n",
      "239690                                              0.823     \n",
      "239691                                              0.541     \n",
      "239692                                              0.789     \n",
      "239693                                              0.531     \n",
      "239694                                              0.763     \n",
      "\n",
      "        t01_smooth_or_features_a02_features_or_disk_weighted_fraction  \\\n",
      "0                                                   0.988               \n",
      "1                                                   0.976               \n",
      "2                                                   0.139               \n",
      "3                                                   0.964               \n",
      "4                                                   0.186               \n",
      "...                                                   ...               \n",
      "239690                                              0.174               \n",
      "239691                                              0.263               \n",
      "239692                                              0.156               \n",
      "239693                                              0.278               \n",
      "239694                                              0.212               \n",
      "\n",
      "        t01_smooth_or_features_a03_star_or_artifact_weighted_fraction  \\\n",
      "0                                                   0.012               \n",
      "1                                                   0.000               \n",
      "2                                                   0.081               \n",
      "3                                                   0.000               \n",
      "4                                                   0.047               \n",
      "...                                                   ...               \n",
      "239690                                              0.003               \n",
      "239691                                              0.197               \n",
      "239692                                              0.055               \n",
      "239693                                              0.191               \n",
      "239694                                              0.025               \n",
      "\n",
      "        t02_edgeon_a04_yes_weighted_fraction  \\\n",
      "0                                      0.048   \n",
      "1                                      0.000   \n",
      "2                                      0.000   \n",
      "3                                      0.037   \n",
      "4                                      0.125   \n",
      "...                                      ...   \n",
      "239690                                 0.857   \n",
      "239691                                 0.000   \n",
      "239692                                 0.000   \n",
      "239693                                 0.000   \n",
      "239694                                 0.200   \n",
      "\n",
      "        t02_edgeon_a05_no_weighted_fraction  \\\n",
      "0                                     0.952   \n",
      "1                                     1.000   \n",
      "2                                     1.000   \n",
      "3                                     0.963   \n",
      "4                                     0.875   \n",
      "...                                     ...   \n",
      "239690                                0.143   \n",
      "239691                                1.000   \n",
      "239692                                1.000   \n",
      "239693                                1.000   \n",
      "239694                                0.800   \n",
      "\n",
      "        t07_rounded_a16_completely_round_weighted_fraction  \\\n",
      "0                                                   0.000    \n",
      "1                                                   1.000    \n",
      "2                                                   0.179    \n",
      "3                                                   1.000    \n",
      "4                                                   0.545    \n",
      "...                                                   ...    \n",
      "239690                                              0.004    \n",
      "239691                                              0.069    \n",
      "239692                                              0.293    \n",
      "239693                                              0.160    \n",
      "239694                                              0.000    \n",
      "\n",
      "        t07_rounded_a17_in_between_weighted_fraction  \\\n",
      "0                                              0.000   \n",
      "1                                              0.000   \n",
      "2                                              0.821   \n",
      "3                                              0.000   \n",
      "4                                              0.455   \n",
      "...                                              ...   \n",
      "239690                                         0.000   \n",
      "239691                                         0.931   \n",
      "239692                                         0.707   \n",
      "239693                                         0.840   \n",
      "239694                                         0.306   \n",
      "\n",
      "        t07_rounded_a18_cigar_shaped_weighted_fraction  \n",
      "0                                                0.000  \n",
      "1                                                0.000  \n",
      "2                                                0.000  \n",
      "3                                                0.000  \n",
      "4                                                0.000  \n",
      "...                                                ...  \n",
      "239690                                           0.996  \n",
      "239691                                           0.000  \n",
      "239692                                           0.000  \n",
      "239693                                           0.000  \n",
      "239694                                           0.694  \n",
      "\n",
      "[239695 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "img_dir=r\"images\"\n",
    "csv_file_number=r\"gz2_filename_mapping.csv\"\n",
    "csv_file_quest=r\"gz2_hart16.csv\"\n",
    "\n",
    "file_number=pd.read_csv(csv_file_number)\n",
    "file_quest=pd.read_csv(csv_file_quest)\n",
    "\n",
    "# We use data from 2 different files: one that maps every image to its id and one that maps every id to the questions answers\n",
    "# So we match every image to the corresponding answers\n",
    "# We have taken the weighted fraction for the answers to questions t01, t02 and t07\n",
    "#  \n",
    "file_merge = file_quest.merge(file_number, left_on='dr7objid', right_on='objid')[['objid', 'asset_id', 't01_smooth_or_features_a01_smooth_weighted_fraction', 't01_smooth_or_features_a02_features_or_disk_weighted_fraction', 't01_smooth_or_features_a03_star_or_artifact_weighted_fraction', 't02_edgeon_a04_yes_weighted_fraction', 't02_edgeon_a05_no_weighted_fraction', 't07_rounded_a16_completely_round_weighted_fraction', 't07_rounded_a17_in_between_weighted_fraction', 't07_rounded_a18_cigar_shaped_weighted_fraction']]\n",
    "\n",
    "print(file_merge)\n",
    "file_merge.to_csv('gz2_merge.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code iterates through the new dataframe and checks which images will open and which cannot open (are probably missing). In the case that the image is missing it will remove its entry from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir=r\"images\"\n",
    "csv_file=r\"gz2_merge.csv\"\n",
    "\n",
    "file=pd.read_csv(csv_file)\n",
    "file['asset_id'] = file['asset_id'].astype(str) + \".jpg\"\n",
    "\n",
    "for ind in file.index:\n",
    "    input_path=os.path.join(img_dir, file['asset_id'][ind])\n",
    "    photo=cv2.imread(input_path)\n",
    "    if photo is None:\n",
    "        file.drop(ind, inplace=True)\n",
    "\n",
    "file.to_csv('existing_images.csv', index= False)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We atributed a type to images. In order for an image to be labeled into a type, we have put the condition that the corresponding weighted fraction should be greater than 0.6 ( basically more than 60% from the people should have labeled it this way). We have created 3 different dataframes corresponding to the classification in raport to questions t01, t02 and t07."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          asset_id  t01_type\n",
      "0        58957.jpg       1.0\n",
      "1       193641.jpg       1.0\n",
      "2        55934.jpg       0.0\n",
      "3       158501.jpg       1.0\n",
      "4       110939.jpg       0.0\n",
      "...            ...       ...\n",
      "209734   30593.jpg       0.0\n",
      "209735   74398.jpg       0.0\n",
      "209736  151540.jpg       0.0\n",
      "209737  259387.jpg       0.0\n",
      "209738  262969.jpg       0.0\n",
      "\n",
      "[209739 rows x 2 columns]\n",
      "          asset_id  t02_type\n",
      "0        58957.jpg       1.0\n",
      "1       193641.jpg       1.0\n",
      "2        55934.jpg       1.0\n",
      "3       158501.jpg       1.0\n",
      "4       110939.jpg       1.0\n",
      "...            ...       ...\n",
      "197172  264076.jpg       0.0\n",
      "197173   30593.jpg       1.0\n",
      "197174  151540.jpg       0.0\n",
      "197175  259387.jpg       1.0\n",
      "197176  262969.jpg       0.0\n",
      "\n",
      "[197177 rows x 2 columns]\n",
      "          asset_id  t07_type\n",
      "0       193641.jpg       0.0\n",
      "1        55934.jpg       1.0\n",
      "2       158501.jpg       0.0\n",
      "3       249897.jpg       1.0\n",
      "4        71801.jpg       1.0\n",
      "...            ...       ...\n",
      "177746  264076.jpg       2.0\n",
      "177747   30593.jpg       0.0\n",
      "177748   74398.jpg       1.0\n",
      "177749  151540.jpg       2.0\n",
      "177750  262969.jpg       2.0\n",
      "\n",
      "[177751 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file.loc [file['t01_smooth_or_features_a01_smooth_weighted_fraction']>0.6, 't01_type'] = 0\n",
    "file.loc [file['t01_smooth_or_features_a02_features_or_disk_weighted_fraction']>0.6, 't01_type'] = 1\n",
    "\n",
    "# Here we have made an exception as the class is extremely sparse so we have labeled it for fractions that are at least 0.5\n",
    "\n",
    "file.loc [file['t01_smooth_or_features_a03_star_or_artifact_weighted_fraction']>=0.5, 't01_type'] = 2\n",
    "\n",
    "file.dropna(inplace=True)\n",
    "file.reset_index(drop=True, inplace=True)\n",
    "t01_file=file[['asset_id','t01_type']].copy()\n",
    "\n",
    "file_modif2=file.copy()\n",
    "file_modif7=file.copy()\n",
    "\n",
    "file_modif2.loc [file['t02_edgeon_a04_yes_weighted_fraction']>0.6, 't02_type'] = 0\n",
    "file_modif2.loc [file['t02_edgeon_a05_no_weighted_fraction']>0.6, 't02_type'] = 1\n",
    "\n",
    "file_modif2.dropna(inplace=True)\n",
    "file_modif2.reset_index(drop=True, inplace=True)\n",
    "t02_file=file_modif2[['asset_id','t02_type']].copy()\n",
    "\n",
    "file_modif7.loc [file['t07_rounded_a16_completely_round_weighted_fraction']>0.6, 't07_type'] = 0\n",
    "file_modif7.loc [file['t07_rounded_a17_in_between_weighted_fraction']>0.6, 't07_type'] = 1\n",
    "file_modif7.loc [file['t07_rounded_a18_cigar_shaped_weighted_fraction']>0.6, 't07_type'] = 2\n",
    "\n",
    "file_modif7.dropna(inplace=True)\n",
    "file_modif7.reset_index(drop=True, inplace=True)\n",
    "t07_file=file_modif7[['asset_id','t07_type']].copy()\n",
    "\n",
    "print(t01_file)\n",
    "print(t02_file)\n",
    "print(t07_file)\n",
    "#t01_file.to_csv('unbalanced_t01.csv',index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now identify how balanced our dataset is by counting how many images correspond to each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t01 type 0 images: 159578\n",
      "t01 type 1 images: 50033\n",
      "t01 type 2 images: 128\n",
      "t02 type 0 images: 21860\n",
      "t02 type 1 images: 175317\n",
      "t07 type 0 images: 59087\n",
      "t07 type 1 images: 93277\n",
      "t07 type 2 images: 25387\n"
     ]
    }
   ],
   "source": [
    "print( f\"t01 type 0 images: { t01_file['t01_type'].value_counts()[0] }\")\n",
    "print( f\"t01 type 1 images: { t01_file['t01_type'].value_counts()[1] }\")\n",
    "print( f\"t01 type 2 images: { t01_file['t01_type'].value_counts()[2] }\")\n",
    "\n",
    "print( f\"t02 type 0 images: { t02_file['t02_type'].value_counts()[0] }\")\n",
    "print( f\"t02 type 1 images: { t02_file['t02_type'].value_counts()[1] }\")\n",
    "\n",
    "print( f\"t07 type 0 images: { t07_file['t07_type'].value_counts()[0] }\")\n",
    "print( f\"t07 type 1 images: { t07_file['t07_type'].value_counts()[1] }\")\n",
    "print( f\"t07 type 2 images: { t07_file['t07_type'].value_counts()[2] }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see t01 type 2 is very sparse so we will habe to perform some data augmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12e04c48ff6cb41451d3b8f61eaea77fdbb7c6edbe7af91566c35ff3203c4846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
